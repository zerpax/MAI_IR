\section{Описание}

В рамках задания была реализована система токенизации текстов документов, предназначенная для дальнейшей индексации и обработки в поисковой системе. Основной целью было разбиение текста на токены и подготовка их к анализу частотных распределений и применению стемминга.

Токенизация выполняется с учётом следующих правил:
\begin{itemize}
    \item Все латинские символы приводятся к нижнему регистру для унификации токенов.
    \item Разделение токенов происходит по символам, не относящимся к буквенно-цифровым или специальным символам: апострофу, дефису и знаку доллара.
    \item Поддерживаются кириллица и символы с диакритикой для расширенного покрытия текстов на разных языках.
\end{itemize}

Метод токенизации имеет следующие достоинства:
\begin{itemize}
    \item Универсальность для нескольких алфавитов.
    \item Сохранение значимых символов (дефис, апостроф, знак доллара) в токенах.
    \item Простая и быстрая реализация на C++ с интеграцией через pybind11.
\end{itemize}

Недостатки метода:
\begin{itemize}
    \item Некорректная обработка некоторых составных слов и сокращений (например, \enquote{it's} может быть токенизировано как \enquote{it} и \enquote{s}).
    \item Невозможность распознавать сложные токены с пунктуацией внутри слова (\enquote{e-mail} обрабатывается корректно, но \enquote{co-op's} разрывается).
    \item Метод чувствителен к нестандартным символам, которые могут присутствовать в веб-тексте.
\end{itemize}

Примеры неудачно выделенных токенов:
\begin{itemize}
    \item \enquote{it's} $\rightarrow$ \enquote{it}, \enquote{s}
    \item \enquote{rock'n'roll} $\rightarrow$ \enquote{rock}, \enquote{n}, \enquote{roll}
\end{itemize}

Для улучшения точности можно:
\begin{itemize}
    \item Использовать более сложные регулярные выражения для сокращений и составных слов.
    \item Применять словарные фильтры для корректной обработки апострофов.
\end{itemize}

Для снижения размерности и унификации терминов была реализована английская стемминг-функция по алгоритму Портера. Она удаляет стандартные окончания и выполняет нормализацию словоформ, что позволяет улучшить сопоставление запросов и документов.

\pagebreak

\section{Статистика токенизации и производительность}

В результате обработки корпуса были получены следующие статистические показатели:
\begin{itemize}
    \item Общее количество токенов: около 16\,753\,371
    \item Средняя длина токена: 4.24 символа.
    \item Время выполнения программы: 3444.1 секунд на корпус объёмом 98.73~МБ.
    \item Зависимость времени от объёма данных близка к линейной.
    \item Скорость токенизации: около 28.67~КБ/сек 
\end{itemize}

Скорость токенизации является достаточной для текущих экспериментов, однако возможны оптимизации:
\begin{itemize}
    \item Использование многопоточности для параллельной обработки документов.
    \item Компиляция алгоритма с флагами оптимизации и SIMD-инструкциями.
    \item Пакетная обработка текста вместо построчной обработки.
\end{itemize}

Для анализа распределения терминов был построен график частот токенов и наложен закон Ципфа (рис.~\ref{fig:zipf}). График показывает, что распределение частот терминов в корпусе публикаций billboard.com и pitchfork.com в целом соответствует закону Ципфа: в лог–лог масштабе реальное распределение близко к линейному. На малых рангах частоты выше теоретических, что объясняется доминированием служебных и общеязыковых слов, а также часто повторяющихся тематических терминов музыкальной журналистики. В средней части распределения наблюдается наилучшее совпадение с моделью Ципфа, что указывает на статистическую устойчивость корпуса. В хвосте распределения частоты убывают быстрее из-за большого числа редких слов, имен собственных и специфических терминов, характерных для тематических медиа-текстов.

\begin{figure}[h!]
\centering
\includegraphics[width=0.7\textwidth]{zipf.png}
\caption{Распределение токенов по частотности и закон Ципфа.}
\label{fig:zipf}
\end{figure}


\pagebreak

\section{Лемматизация и стемминг}

Для повышения качества поиска была внедрена стемминг-функция на основе алгоритма Портера. Стемминг применяется на этапе индексации: все токены приводятся к базовой форме. Это позволяет:
\begin{itemize}
    \item Объединять разные словоформы одного слова в один токен.
    \item Повысить релевантность результатов поиска.
\end{itemize}

Оценка качества поиска показала улучшение точности при поиске по общим запросам. В некоторых случаях качество ухудшилось:
\begin{itemize}
    \item Токены с одинаковыми окончаниями, но разным смыслом (\enquote{organization} и \enquote{organ}) объединялись, что снижало релевантность.
\end{itemize}

Для решения этой проблемы можно внедрить комбинированный подход: использовать стемминг для индексации, но при ранжировании учитывать полные словоформы с бонусом за точное совпадение.
