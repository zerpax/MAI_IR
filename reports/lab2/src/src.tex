\section{Описание}

В рамках второго домашнего задания был реализован поисковый робот, предназначенный для автоматической обкачки веб-документов и сохранения их в базе данных. Поисковый робот используется для сбора HTML-страниц с заданных источников и может быть применён в дальнейшем для формирования корпуса документов и проведения экспериментов в области информационного поиска.

Робот принимает на вход путь к YAML-конфигурационному файлу, содержащему параметры подключения к базе данных, а также настройки логики обхода. Такой подход позволяет гибко настраивать работу робота без изменения исходного кода и соответствует требованиям задания.

В конфигурационном файле задаются параметры подключения к базе данных MongoDB, включая адрес сервера, имя базы данных и коллекции. Также в секции логики указываются начальный URL для обхода, допустимые страницы для перехода, глубина обхода, задержка между запросами и вспомогательные параметры, необходимые для корректной работы робота.

Поисковый робот осуществляет последовательный обход страниц, начиная с заданного стартового URL. Для каждой страницы выполняется HTTP-запрос с указанием пользовательского агента, после чего полученный HTML-код анализируется. Если страница удовлетворяет условиям обработки, её содержимое сохраняется в базе данных.

Каждый документ в базе данных содержит следующие поля:
\begin{itemize}
    \item нормализованный URL страницы;
    \item «сырой» HTML-текст документа;
    \item название источника, определяемое по доменному имени;
    \item дата обкачки документа.
\end{itemize}

Для обеспечения возможности повторного запуска робота реализован механизм продолжения обхода. При старте робот считывает уже сохранённые URL из базы данных и не обрабатывает их повторно. Текущая позиция обхода и идентификаторы документов сохраняются в конфигурационном файле, что позволяет продолжить работу с места остановки в случае прерывания выполнения.

Для поддержки переобкачки документов реализована проверка изменений содержимого страниц. Для каждого HTML-документа вычисляется хеш-сумма, которая сохраняется в базе данных. При повторной обкачке страницы новая хеш-сумма сравнивается с ранее сохранённой. Если содержимое страницы изменилось, документ в базе данных обновляется, а дата обкачки перезаписывается. Если изменений не обнаружено, обновление документа не производится.

Между запросами к серверу используется настраиваемая задержка, что позволяет снизить нагрузку на обрабатываемые сайты и соответствует принципам корректного веб-сканирования.

Таким образом, реализованный поисковый робот удовлетворяет всем требованиям задания: использует конфигурационный файл, сохраняет необходимые данные в базе, поддерживает возобновление работы и умеет переобкачивать изменённые документы.

\pagebreak

\section{Исходный код}

Поисковый робот реализован на языке Python с использованием стандартных и сторонних библиотек для работы с HTTP-запросами, HTML-документами, конфигурационными файлами и базой данных MongoDB.

Программа начинается с загрузки конфигурационного файла в формате YAML, из которого извлекаются параметры подключения к базе данных и настройки логики обхода. Подключение к MongoDB осуществляется при помощи соответствующей клиентской библиотеки.

Основная логика робота реализована в виде цикла обхода страниц. Для каждой страницы выполняется HTTP-запрос, после чего HTML-документ разбирается и анализируется. Из документа извлекаются ссылки, которые нормализуются и добавляются в очередь обхода при условии, что они соответствуют заданным ограничениям.

Для хранения состояния обхода используется база данных и конфигурационный файл. Уже посещённые страницы учитываются при помощи выборки URL из базы данных, что предотвращает повторную обработку документов. В случае прерывания работы робота текущее состояние сохраняется, что позволяет продолжить обход при следующем запуске.

Для контроля актуальности документов используется вычисление хеш-суммы HTML-кода страницы. Это позволяет эффективно определять, изменилось ли содержимое документа, и обновлять данные в базе только при необходимости.

Результатом работы программы является база данных, содержащая актуальные HTML-документы с информацией об источнике и времени обкачки, готовая для дальнейшей обработки и использования в задачах информационного поиска.
